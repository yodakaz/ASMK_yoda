{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/yodakaz/ASMK_yoda/blob/main/how/Github%E3%81%8B%E3%82%89%E5%AE%9F%E8%A1%8C5.1.ipynb",
      "authorship_tag": "ABX9TyPZCswiD5OXYFD05YaMnPwA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yodakaz/ASMK_yoda/blob/main/how/Github%E3%81%8B%E3%82%89%E5%AE%9F%E8%A1%8C5.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elBur5KeY4DZ"
      },
      "source": [
        "# clone 失敗等によるフォルダ削除用\n",
        "import shutil\n",
        "\n",
        "directory = '/content/how/how_experiments'\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(directory)\n",
        "except FileNotFoundError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCt_R1CzqGIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6fd769-60d5-4149-9122-4237f5b0cfed"
      },
      "source": [
        "# 修正済みプログラムのclone\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/yodakaz/ASMK_yoda.git\n",
        "\n",
        "# howをcontent直下へ移動\n",
        "# google driveのマウント"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ASMK_yoda'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "remote: Counting objects: 100% (243/243), done.\u001b[K\n",
            "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
            "remote: Total 243 (delta 43), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (243/243), 964.36 KiB | 6.10 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWmTGKQGqcAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a49951ee-0dcf-4259-9017-39d59bbce4e9"
      },
      "source": [
        "# temp.pthファイルをgoogle driveからコピー\n",
        "import shutil\n",
        "shutil.copytree(\"/content/drive/MyDrive/ASMK/how_temp\", \"/content/how/how_temp\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/how/how_temp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhtbyezYnZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487e01c3-acfa-4fe8-b5db-a0b393aa2c20"
      },
      "source": [
        "# 元コードおよびデータ clone\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#!git clone https://github.com/gtolias/how.git\n",
        "\n",
        "!git clone https://github.com/MING410/local #データセットのclone"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'local'...\n",
            "remote: Enumerating objects: 5839, done.\u001b[K\n",
            "remote: Counting objects: 100% (1934/1934), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 5839 (delta 1799), reused 1934 (delta 1799), pack-reused 3905\u001b[K\n",
            "Receiving objects: 100% (5839/5839), 468.04 MiB | 37.61 MiB/s, done.\n",
            "Resolving deltas: 100% (3689/3689), done.\n",
            "Checking out files: 100% (7539/7539), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Sf-klxKWtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090b237b-3ac5-4410-a652-af770f51e82a"
      },
      "source": [
        "# cirtorch\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "!wget \"https://github.com/filipradenovic/cnnimageretrieval-pytorch/archive/v1.2.zip\"\n",
        "!unzip v1.2.zip\n",
        "!rm v1.2.zip\n",
        "!export PYTHONPATH=${PYTHONPATH}:$(realpath cnnimageretrieval-pytorch-1.2)\n",
        "\n",
        "#\"cirtorh\"をhowに入れる"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 23:52:03--  https://github.com/filipradenovic/cnnimageretrieval-pytorch/archive/v1.2.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/filipradenovic/cnnimageretrieval-pytorch/zip/v1.2 [following]\n",
            "--2021-07-11 23:52:03--  https://codeload.github.com/filipradenovic/cnnimageretrieval-pytorch/zip/v1.2\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v1.2.zip’\n",
            "\n",
            "v1.2.zip                [ <=>                ]  41.06K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-07-11 23:52:03 (6.77 MB/s) - ‘v1.2.zip’ saved [42048]\n",
            "\n",
            "Archive:  v1.2.zip\n",
            "7da5c2a8c7e6d27ac652d1de137d17df31cb510a\n",
            "   creating: cnnimageretrieval-pytorch-1.2/\n",
            "  inflating: cnnimageretrieval-pytorch-1.2/LICENSE  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/README.md  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/\n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/__init__.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/datahelpers.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/genericdataset.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/testdataset.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/traindataset.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/examples/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/example_descriptor_extraction.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/test.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/test_e2e.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/train.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/layers/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/functional.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/loss.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/normalization.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/pooling.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/networks/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/networks/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/networks/imageretrievalnet.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/utils/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/download.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/download_win.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/evaluate.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/general.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/whiten.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVfZ0Y_Ke2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65efbe3a-650d-4942-c2e7-2f582555f4e7"
      },
      "source": [
        "# asmk\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "#!git clone https://github.com/jenicek/asmk.git\n",
        "!pip3 install pyaml numpy faiss-gpu\n",
        "#!cd asmk\n",
        "#!python3 /content/asmk/setup.py build_ext --inplace\n",
        "#!rm -r build\n",
        "#!cd ..\n",
        "#!export PYTHONPATH=${PYTHONPATH}:$(realpath asmk)\n",
        "#\"asmk\"(全体)をhowにいれる"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting faiss-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/20/cce8f99dde167453ea108f35cd4bfffcc318a314aaf1bdfb167f6be2c989/faiss_gpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml) (3.13)\n",
            "Installing collected packages: pyaml, faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1.post2 pyaml-20.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEvnMVqAKni5"
      },
      "source": [
        "#不足があれば \n",
        "#(pytorchの要求バージョンが古い)\n",
        "import os\n",
        "os.chdir('/content/how')\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7L5OAQ2nBgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb002806-2807-4506-bfa2-d754c11d895b"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/how/asmk/cython')\n",
        "#/content/how/asmk/cython/setup.py を作成\n",
        "#setup.py (cython実行用)の中身\n",
        "\"\"\"\n",
        "from distutils.core import setup, Extension \n",
        "from Cython.Build import cythonize \n",
        "from numpy import get_include # cimport numpy を使うため\n",
        "\n",
        "ext = Extension(\"hamming\", sources=[\"hamming.pyx\"], include_dirs=['.', get_include()])\n",
        "setup(name=\"hamming\", ext_modules=cythonize([ext]))\n",
        "\"\"\"\n",
        "#実行\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "building 'hamming' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c hamming.c -o build/temp.linux-x86_64-3.7/hamming.o\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/hamming.o -o /content/how/asmk/cython/hamming.cpython-37m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlII0dUnTSHF"
      },
      "source": [
        "# ローカルへ保存用\n",
        "!zip -r /content/exp_0712_2.zip /content/how/how_data/experiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PWxCO1MmSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a45a28b-1d90-4b4d-ff3c-ec84936a9d21"
      },
      "source": [
        "#コードの実行\n",
        "import os\n",
        "os.chdir('/content/how')\n",
        "\n",
        "########### 元コード変更箇所 ##################################################\n",
        "#./stage/evaluate.py:asmk.asmk_method→asmk.asmk.asmk_method\n",
        "#./asmk/kernel.py:import . →import ..cython from hamming\n",
        "#./examples/demo_how.py:(L90)コメントアウト(自前データセット使用のため)\n",
        "#./how/utils/data_helper.py:(L14～)training_set = 'mitsubishi_dataset'\n",
        "#                           ims_root:'ims' → 'png_images'\n",
        "#                           db = pickle.load(f)#['train'] ← コメントアウト\n",
        "#       同  elif dataset == 'val_eccv20':\n",
        "#              db_root,  fn_val_proper, ims_root を変更\n",
        "#              ※fn_val_proper = db_root+'/mitsubishi_dataset_val-eccv2020.pkl'\n",
        "#./cirtorch/datasets/datahelper.py:return os.path.join()変更\n",
        "#./cirtorch/datasets/traindataset.py:(L50～).ymlから読み込んだ情報修正\n",
        "#if name == 'retrieval-SfM-120k':\n",
        "#  print(\"changed retrieval-SfM-120k => mitsubishi_dataset\")\n",
        "#  name = 'mitsubishi_dataset'\n",
        "#ims_rootの'ims' → 'png_images'\n",
        "#db = pickle.load(f)#[mode] ←コメントアウト\n",
        "#/conent/how/how_data/train/mitsubishi_dataset作成\n",
        "#\".pkl\"ファイル2つとlocalからpng_images移動\n",
        "# /how/how_tempを作成\n",
        "\n",
        "#!python3 examples/demo_how.py eval examples/params/eccv20/eval_how_r18_1000.yml -e official_how_r18_1000\n",
        "!python3 examples/demo_how.py train examples/params/eccv20/train_how_r18.yml -e train_how_r18"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:02<00:00, 19.5MB/s]\n",
            "HOW INFO: Initializing network whitening\n",
            ">> Initializing dim reduction\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            ">>>> 1885/1885 done...\n",
            "tcmalloc: large alloc 2841313280 bytes == 0x560421224000 @  0x7effee4161e7 0x7eff9181946e 0x7eff91869c7b 0x7eff91869d18 0x7eff91911010 0x7eff9191173c 0x7eff9191185d 0x5602de645f68 0x7eff91856ef7 0x5602de643c47 0x5602de643a50 0x5602de6b7453 0x5602de6b24ae 0x5602de6453ea 0x5602de6b77f0 0x5602de584d14 0x7eff91856ef7 0x5602de643c47 0x5602de643a50 0x5602de6b7453 0x5602de6b24ae 0x5602de6453ea 0x5602de6b77f0 0x5602de6b27ad 0x5602de6453ea 0x5602de6b432a 0x5602de6b27ad 0x5602de584e2c 0x5602de6b4bb5 0x5602de6b24ae 0x5602de584e2c\n",
            "tcmalloc: large alloc 2841313280 bytes == 0x5604ca7d4000 @  0x7effee4161e7 0x7eff9181946e 0x7eff91869c7b 0x7eff91869d18 0x7eff91925d79 0x7eff91928e4c 0x7eff91a47e7f 0x7eff91a4dfb5 0x7eff91a4fe3d 0x7eff91a51516 0x5602de644f30 0x5602de644b09 0x7eff919300db 0x5602de72d252 0x5602de6b40d2 0x5602de6b24ae 0x5602de6453ea 0x5602de6b77f0 0x5602de64530a 0x5602de6b77f0 0x5602de6b24ae 0x5602de584e2c 0x5602de6b4bb5 0x5602de6b24ae 0x5602de584e2c 0x5602de6b4bb5 0x5602de64530a 0x5602de6b33b5 0x5602de6b24ae 0x5602de6b21b3 0x5602de77c182\n",
            "changed retrieval-SfM-120k => mitsubishi_dataset\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4694560178825932), (2, 0.40608791410923006), (3, 0.37607302958926847), (4, 0.35423485444438074), (5, 0.33237718728280835)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.33237718728280835\n",
            "######loaded at 5#######\n",
            "HOW INFO: Starting asmk evaluation\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 1885/1885 done...\n",
            "WARNING clustering 1387360 points to 65536 centroids: please provide at least 2555904 training points\n",
            "HOW INFO: Codebook trained in 112.1s\n",
            "HOW INFO: Evaluating 'val_eccv20'\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            ">>>> 1885/1885 done...\n",
            "HOW INFO: Indexed images in 37.16s\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 980/980 done...\n",
            "HOW INFO: Evaluated val_eccv20: mAP 16.8, mP@k [36.84 23.85 21.02]\n",
            "HOW INFO: Finished asmk evaluation in 12 min\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.16804500412893747)]}), 'train_loss': [(1, 0.4694560178825932), (2, 0.40608791410923006), (3, 0.37607302958926847), (4, 0.35423485444438074), (5, 0.33237718728280835)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.33237718728280835\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7eff60a71090>\n",
            "######saved after 5#######\n",
            "HOW INFO: Epoch 5 finished in 769.4s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}