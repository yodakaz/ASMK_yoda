{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/yodakaz/ASMK_yoda/blob/main/how/Github%E3%81%8B%E3%82%89%E5%AE%9F%E8%A1%8C5.1.ipynb",
      "authorship_tag": "ABX9TyNmnGCAikwYSNI2NWFKukrS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yodakaz/ASMK_yoda/blob/main/how/Github%E3%81%8B%E3%82%89%E5%AE%9F%E8%A1%8C5.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elBur5KeY4DZ"
      },
      "source": [
        "# clone 失敗等によるフォルダ削除用\n",
        "import shutil\n",
        "\n",
        "directory = '/content/how/how_temp'\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(directory)\n",
        "except FileNotFoundError:\n",
        "    pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCt_R1CzqGIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a336d7c-b92d-43ca-8cad-9c5b8d0713a7"
      },
      "source": [
        "# 修正済みプログラムのclone\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/yodakaz/ASMK_yoda.git\n",
        "\n",
        "# howをcontent直下へ移動\n",
        "# google driveのマウント"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ASMK_yoda'...\n",
            "remote: Enumerating objects: 260, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 260 (delta 0), reused 0 (delta 0), pack-reused 254\u001b[K\n",
            "Receiving objects: 100% (260/260), 972.26 KiB | 14.73 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWmTGKQGqcAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cf7de4ac-cd5c-42db-d0fc-953e2ff21a44"
      },
      "source": [
        "# temp.pthファイルをgoogle driveからコピー\n",
        "import shutil\n",
        "shutil.copytree(\"/content/drive/MyDrive/ASMK/how_temp\", \"/content/how/how_temp\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/how/how_temp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gif5aJAIkT7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18ae8761-768b-4302-f283-fba943a107f6"
      },
      "source": [
        "# Colabで学習した場合\n",
        "# temp.pthファイルをgoogle driveへコピー\n",
        "import shutil\n",
        "shutil.copyfile(\"/content/how/how_temp/temp.pth\", \"/content/drive/MyDrive/ASMK/how_temp/temp(20210719).pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ASMK/how_temp/temp(20210719).pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhtbyezYnZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91aaf919-9bfd-4e01-f187-5fb708f65923"
      },
      "source": [
        "# 元コードおよびデータ clone\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#!git clone https://github.com/gtolias/how.git\n",
        "\n",
        "!git clone https://github.com/MING410/local #データセットのclone"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'local'...\n",
            "remote: Enumerating objects: 5839, done.\u001b[K\n",
            "remote: Counting objects: 100% (1934/1934), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 5839 (delta 1799), reused 1934 (delta 1799), pack-reused 3905\u001b[K\n",
            "Receiving objects: 100% (5839/5839), 468.04 MiB | 34.70 MiB/s, done.\n",
            "Resolving deltas: 100% (3689/3689), done.\n",
            "Checking out files: 100% (7539/7539), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Sf-klxKWtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090b237b-3ac5-4410-a652-af770f51e82a"
      },
      "source": [
        "# cirtorch\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "!wget \"https://github.com/filipradenovic/cnnimageretrieval-pytorch/archive/v1.2.zip\"\n",
        "!unzip v1.2.zip\n",
        "!rm v1.2.zip\n",
        "!export PYTHONPATH=${PYTHONPATH}:$(realpath cnnimageretrieval-pytorch-1.2)\n",
        "\n",
        "#\"cirtorh\"をhowに入れる"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 23:52:03--  https://github.com/filipradenovic/cnnimageretrieval-pytorch/archive/v1.2.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/filipradenovic/cnnimageretrieval-pytorch/zip/v1.2 [following]\n",
            "--2021-07-11 23:52:03--  https://codeload.github.com/filipradenovic/cnnimageretrieval-pytorch/zip/v1.2\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v1.2.zip’\n",
            "\n",
            "v1.2.zip                [ <=>                ]  41.06K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-07-11 23:52:03 (6.77 MB/s) - ‘v1.2.zip’ saved [42048]\n",
            "\n",
            "Archive:  v1.2.zip\n",
            "7da5c2a8c7e6d27ac652d1de137d17df31cb510a\n",
            "   creating: cnnimageretrieval-pytorch-1.2/\n",
            "  inflating: cnnimageretrieval-pytorch-1.2/LICENSE  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/README.md  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/\n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/__init__.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/datahelpers.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/genericdataset.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/testdataset.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/traindataset.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/examples/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/example_descriptor_extraction.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/test.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/test_e2e.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/train.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/layers/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/functional.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/loss.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/normalization.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/pooling.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/networks/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/networks/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/networks/imageretrievalnet.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/utils/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/download.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/download_win.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/evaluate.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/general.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/whiten.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVfZ0Y_Ke2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6996c0c-774a-462a-cc7d-d912b2835580"
      },
      "source": [
        "# asmk\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "#!git clone https://github.com/jenicek/asmk.git\n",
        "!pip3 install pyaml numpy faiss-gpu\n",
        "#!cd asmk\n",
        "#!python3 /content/asmk/setup.py build_ext --inplace\n",
        "#!rm -r build\n",
        "#!cd ..\n",
        "#!export PYTHONPATH=${PYTHONPATH}:$(realpath asmk)\n",
        "#\"asmk\"(全体)をhowにいれる"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaml\n",
            "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7 MB 5.0 kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml) (3.13)\n",
            "Installing collected packages: pyaml, faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1.post2 pyaml-20.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEvnMVqAKni5"
      },
      "source": [
        "#不足があれば \n",
        "#(pytorchの要求バージョンが古い)\n",
        "import os\n",
        "os.chdir('/content/how')\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7L5OAQ2nBgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb002806-2807-4506-bfa2-d754c11d895b"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/how/asmk/cython')\n",
        "#/content/how/asmk/cython/setup.py を作成\n",
        "#setup.py (cython実行用)の中身\n",
        "\"\"\"\n",
        "from distutils.core import setup, Extension \n",
        "from Cython.Build import cythonize \n",
        "from numpy import get_include # cimport numpy を使うため\n",
        "\n",
        "ext = Extension(\"hamming\", sources=[\"hamming.pyx\"], include_dirs=['.', get_include()])\n",
        "setup(name=\"hamming\", ext_modules=cythonize([ext]))\n",
        "\"\"\"\n",
        "#実行\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "building 'hamming' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c hamming.c -o build/temp.linux-x86_64-3.7/hamming.o\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/hamming.o -o /content/how/asmk/cython/hamming.cpython-37m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlII0dUnTSHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51edfb1f-85c5-49b4-97f2-78e3bfa468c1"
      },
      "source": [
        "# ローカルへ保存用\n",
        "!zip -r /content/exp_0719.zip /content/how/how_data/experiments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/how/how_data/experiments/ (stored 0%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/ (stored 0%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/query_results.pkl (deflated 60%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/train_params.yml (deflated 58%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/fig_train.jpg (deflated 25%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/train.log (deflated 73%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/epochs/ (stored 0%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/epochs/model_best.pth (deflated 7%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/fig_val_local_descriptor.jpg (deflated 51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PWxCO1MmSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48697869-3a27-4e70-f393-21e03ebb40ea"
      },
      "source": [
        "#コードの実行\n",
        "import os\n",
        "os.chdir('/content/how')\n",
        "\n",
        "########### 元コード変更箇所 ##################################################\n",
        "#./stage/evaluate.py:asmk.asmk_method→asmk.asmk.asmk_method\n",
        "#./asmk/kernel.py:import . →import ..cython from hamming\n",
        "#./examples/demo_how.py:(L90)コメントアウト(自前データセット使用のため)\n",
        "#./how/utils/data_helper.py:(L14～)training_set = 'mitsubishi_dataset'\n",
        "#                           ims_root:'ims' → 'png_images'\n",
        "#                           db = pickle.load(f)#['train'] ← コメントアウト\n",
        "#       同  elif dataset == 'val_eccv20':\n",
        "#              db_root,  fn_val_proper, ims_root を変更\n",
        "#              ※fn_val_proper = db_root+'/mitsubishi_dataset_val-eccv2020.pkl'\n",
        "#./cirtorch/datasets/datahelper.py:return os.path.join()変更\n",
        "#./cirtorch/datasets/traindataset.py:(L50～).ymlから読み込んだ情報修正\n",
        "#if name == 'retrieval-SfM-120k':\n",
        "#  print(\"changed retrieval-SfM-120k => mitsubishi_dataset\")\n",
        "#  name = 'mitsubishi_dataset'\n",
        "#ims_rootの'ims' → 'png_images'\n",
        "#db = pickle.load(f)#[mode] ←コメントアウト\n",
        "#/conent/how/how_data/train/mitsubishi_dataset作成\n",
        "#\".pkl\"ファイル2つとlocalからpng_images移動\n",
        "# /how/how_tempを作成\n",
        "\n",
        "# eval 変更点(/stages/evaluate.py l29,30)\n",
        "#    print(\"demo_eval['net_path'] = 'train_how_r18/epochs/model_epoch20.pth'\")\n",
        "#    demo_eval['net_path'] = 'train_how_r18/epochs/model_epoch20.pth'\n",
        "\n",
        "#!python3 examples/demo_how.py eval examples/params/eccv20/eval_how_r18_1000.yml -e official_how_r18_1000\n",
        "!python3 examples/demo_how.py train examples/params/eccv20/train_how_r18.yml -e train_how_r18"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "demo_eval['net_path'] = 'train_how_r18/epochs/model_epoch20.pth'\n",
            "HOW INFO: Starting asmk evaluation\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            ">>>> 989/989 done...\n",
            "WARNING clustering 727904 points to 65536 centroids: please provide at least 2555904 training points\n",
            "HOW INFO: Codebook trained in 53.6s\n",
            "HOW INFO: Evaluating 'val_eccv20'\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            ">>>> 657/657 done...\n",
            "HOW INFO: Indexed images in 13.71s\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 239/239 done...\n",
            "HOW INFO: Evaluated val_eccv20: mAP 46.44, mP@k [76.15 52.5  42.9 ]\n",
            "Traceback (most recent call last):\n",
            "  File \"examples/demo_how.py\", line 111, in <module>\n",
            "    main(sys.argv[1:])\n",
            "  File \"examples/demo_how.py\", line 95, in main\n",
            "    evaluate.evaluate_demo(**params, globals=globals)\n",
            "  File \"/content/how/how/stages/evaluate.py\", line 54, in evaluate_demo\n",
            "    eval_asmk(net, evaluation['inference'], globals, **evaluation['local_descriptor'])\n",
            "  File \"/content/how/how/stages/evaluate.py\", line 100, in eval_asmk\n",
            "    images, qimages, bbxs, gnd = data_helpers.load_dataset(dataset, data_root=globals['root_path'])\n",
            "  File \"/content/how/how/utils/data_helpers.py\", line 53, in load_dataset\n",
            "    cfg = configdataset(dataset, os.path.join(data_root, 'test'))\n",
            "  File \"/content/how/cirtorch/datasets/testdataset.py\", line 15, in configdataset\n",
            "    with open(gnd_fname, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/how/how_data/test/roxford5k/gnd_roxford5k.pkl'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}