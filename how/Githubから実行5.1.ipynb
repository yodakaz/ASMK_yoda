{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/yodakaz/ASMK_yoda/blob/main/how/Github%E3%81%8B%E3%82%89%E5%AE%9F%E8%A1%8C5.1.ipynb",
      "authorship_tag": "ABX9TyPAldesCi6wjKTPORJv6Sqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yodakaz/ASMK_yoda/blob/main/how/Github%E3%81%8B%E3%82%89%E5%AE%9F%E8%A1%8C5.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elBur5KeY4DZ"
      },
      "source": [
        "# clone 失敗等によるフォルダ削除用\n",
        "import shutil\n",
        "\n",
        "directory = '/content/how/how_temp'\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(directory)\n",
        "except FileNotFoundError:\n",
        "    pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCt_R1CzqGIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a336d7c-b92d-43ca-8cad-9c5b8d0713a7"
      },
      "source": [
        "# 修正済みプログラムのclone\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/yodakaz/ASMK_yoda.git\n",
        "\n",
        "# howをcontent直下へ移動\n",
        "# google driveのマウント"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ASMK_yoda'...\n",
            "remote: Enumerating objects: 260, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 260 (delta 0), reused 0 (delta 0), pack-reused 254\u001b[K\n",
            "Receiving objects: 100% (260/260), 972.26 KiB | 14.73 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWmTGKQGqcAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cf7de4ac-cd5c-42db-d0fc-953e2ff21a44"
      },
      "source": [
        "# temp.pthファイルをgoogle driveからコピー\n",
        "import shutil\n",
        "shutil.copytree(\"/content/drive/MyDrive/ASMK/how_temp\", \"/content/how/how_temp\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/how/how_temp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gif5aJAIkT7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e2b8529e-34c2-4d99-99e8-d993d0d36404"
      },
      "source": [
        "# Colabで学習した場合\n",
        "# temp.pthファイルをgoogle driveへコピー\n",
        "import shutil\n",
        "#shutil.copyfile(\"/content/how/how_temp/temp.pth\", \"/content/drive/MyDrive/ASMK/how_temp/temp(20210720).pth\")\n",
        "shutil.copytree(\"/content/how/how_data/experiments\", \"/content/drive/MyDrive/ASMK/exp(20210720)\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ASMK/exp(20210720)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhtbyezYnZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91aaf919-9bfd-4e01-f187-5fb708f65923"
      },
      "source": [
        "# 元コードおよびデータ clone\n",
        "import os\n",
        "os.chdir('/content')\n",
        "#!git clone https://github.com/gtolias/how.git\n",
        "\n",
        "!git clone https://github.com/MING410/local #データセットのclone"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'local'...\n",
            "remote: Enumerating objects: 5839, done.\u001b[K\n",
            "remote: Counting objects: 100% (1934/1934), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 5839 (delta 1799), reused 1934 (delta 1799), pack-reused 3905\u001b[K\n",
            "Receiving objects: 100% (5839/5839), 468.04 MiB | 34.70 MiB/s, done.\n",
            "Resolving deltas: 100% (3689/3689), done.\n",
            "Checking out files: 100% (7539/7539), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Sf-klxKWtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090b237b-3ac5-4410-a652-af770f51e82a"
      },
      "source": [
        "# cirtorch\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "!wget \"https://github.com/filipradenovic/cnnimageretrieval-pytorch/archive/v1.2.zip\"\n",
        "!unzip v1.2.zip\n",
        "!rm v1.2.zip\n",
        "!export PYTHONPATH=${PYTHONPATH}:$(realpath cnnimageretrieval-pytorch-1.2)\n",
        "\n",
        "#\"cirtorh\"をhowに入れる"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 23:52:03--  https://github.com/filipradenovic/cnnimageretrieval-pytorch/archive/v1.2.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/filipradenovic/cnnimageretrieval-pytorch/zip/v1.2 [following]\n",
            "--2021-07-11 23:52:03--  https://codeload.github.com/filipradenovic/cnnimageretrieval-pytorch/zip/v1.2\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v1.2.zip’\n",
            "\n",
            "v1.2.zip                [ <=>                ]  41.06K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-07-11 23:52:03 (6.77 MB/s) - ‘v1.2.zip’ saved [42048]\n",
            "\n",
            "Archive:  v1.2.zip\n",
            "7da5c2a8c7e6d27ac652d1de137d17df31cb510a\n",
            "   creating: cnnimageretrieval-pytorch-1.2/\n",
            "  inflating: cnnimageretrieval-pytorch-1.2/LICENSE  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/README.md  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/\n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/__init__.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/datahelpers.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/genericdataset.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/testdataset.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/datasets/traindataset.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/examples/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/example_descriptor_extraction.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/test.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/test_e2e.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/examples/train.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/layers/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/functional.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/loss.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/normalization.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/layers/pooling.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/networks/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/networks/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/networks/imageretrievalnet.py  \n",
            "   creating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/\n",
            " extracting: cnnimageretrieval-pytorch-1.2/cirtorch/utils/__init__.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/download.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/download_win.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/evaluate.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/general.py  \n",
            "  inflating: cnnimageretrieval-pytorch-1.2/cirtorch/utils/whiten.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVfZ0Y_Ke2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6996c0c-774a-462a-cc7d-d912b2835580"
      },
      "source": [
        "# asmk\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "#!git clone https://github.com/jenicek/asmk.git\n",
        "!pip3 install pyaml numpy faiss-gpu\n",
        "#!cd asmk\n",
        "#!python3 /content/asmk/setup.py build_ext --inplace\n",
        "#!rm -r build\n",
        "#!cd ..\n",
        "#!export PYTHONPATH=${PYTHONPATH}:$(realpath asmk)\n",
        "#\"asmk\"(全体)をhowにいれる"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaml\n",
            "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.1.post2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7 MB 5.0 kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml) (3.13)\n",
            "Installing collected packages: pyaml, faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1.post2 pyaml-20.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEvnMVqAKni5"
      },
      "source": [
        "#不足があれば \n",
        "#(pytorchの要求バージョンが古い)\n",
        "import os\n",
        "os.chdir('/content/how')\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7L5OAQ2nBgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb002806-2807-4506-bfa2-d754c11d895b"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/how/asmk/cython')\n",
        "#/content/how/asmk/cython/setup.py を作成\n",
        "#setup.py (cython実行用)の中身\n",
        "\"\"\"\n",
        "from distutils.core import setup, Extension \n",
        "from Cython.Build import cythonize \n",
        "from numpy import get_include # cimport numpy を使うため\n",
        "\n",
        "ext = Extension(\"hamming\", sources=[\"hamming.pyx\"], include_dirs=['.', get_include()])\n",
        "setup(name=\"hamming\", ext_modules=cythonize([ext]))\n",
        "\"\"\"\n",
        "#実行\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "building 'hamming' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I. -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c hamming.c -o build/temp.linux-x86_64-3.7/hamming.o\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/hamming.o -o /content/how/asmk/cython/hamming.cpython-37m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlII0dUnTSHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51edfb1f-85c5-49b4-97f2-78e3bfa468c1"
      },
      "source": [
        "# ローカルへ保存用\n",
        "!zip -r /content/exp_0719.zip /content/how/how_data/experiments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/how/how_data/experiments/ (stored 0%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/ (stored 0%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/query_results.pkl (deflated 60%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/train_params.yml (deflated 58%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/fig_train.jpg (deflated 25%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/train.log (deflated 73%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/epochs/ (stored 0%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/epochs/model_best.pth (deflated 7%)\n",
            "  adding: content/how/how_data/experiments/train_how_r18/fig_val_local_descriptor.jpg (deflated 51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PWxCO1MmSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089867da-9335-45ee-bee1-86c10a7c2c09"
      },
      "source": [
        "#コードの実行\n",
        "import os\n",
        "os.chdir('/content/how')\n",
        "\n",
        "########### 元コード変更箇所 ##################################################\n",
        "#./stage/evaluate.py:asmk.asmk_method→asmk.asmk.asmk_method\n",
        "#./asmk/kernel.py:import . →import ..cython from hamming\n",
        "#./examples/demo_how.py:(L90)コメントアウト(自前データセット使用のため)\n",
        "#./how/utils/data_helper.py:(L14～)training_set = 'mitsubishi_dataset'\n",
        "#                           ims_root:'ims' → 'png_images'\n",
        "#                           db = pickle.load(f)#['train'] ← コメントアウト\n",
        "#       同  elif dataset == 'val_eccv20':\n",
        "#              db_root,  fn_val_proper, ims_root を変更\n",
        "#              ※fn_val_proper = db_root+'/mitsubishi_dataset_val-eccv2020.pkl'\n",
        "#./cirtorch/datasets/datahelper.py:return os.path.join()変更\n",
        "#./cirtorch/datasets/traindataset.py:(L50～).ymlから読み込んだ情報修正\n",
        "#if name == 'retrieval-SfM-120k':\n",
        "#  print(\"changed retrieval-SfM-120k => mitsubishi_dataset\")\n",
        "#  name = 'mitsubishi_dataset'\n",
        "#ims_rootの'ims' → 'png_images'\n",
        "#db = pickle.load(f)#[mode] ←コメントアウト\n",
        "#/conent/how/how_data/train/mitsubishi_dataset作成\n",
        "#\".pkl\"ファイル2つとlocalからpng_images移動\n",
        "# /how/how_tempを作成\n",
        "\n",
        "# eval 変更点(/stages/evaluate.py l29,30)\n",
        "#    print(\"demo_eval['net_path'] = 'train_how_r18/epochs/model_epoch20.pth'\")\n",
        "#    demo_eval['net_path'] = 'train_how_r18/epochs/model_epoch20.pth'\n",
        "\n",
        "#!python3 examples/demo_how.py eval examples/params/eccv20/eval_how_r18_1000.yml -e official_how_r18_1000\n",
        "!python3 examples/demo_how.py train examples/params/eccv20/train_how_r18.yml -e train_how_r18"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HOW INFO: Initializing network whitening\n",
            ">> Initializing dim reduction\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            ">>>> 989/989 done...\n",
            "tcmalloc: large alloc 1490747392 bytes == 0x56200192c000 @  0x7fa2012db1e7 0x7fa1a46de46e 0x7fa1a472ec7b 0x7fa1a472ed18 0x7fa1a47d6010 0x7fa1a47d673c 0x7fa1a47d685d 0x561f106292b8 0x7fa1a471bef7 0x561f10626f97 0x561f10626da0 0x561f1069abb3 0x561f10695c35 0x561f1062873a 0x561f1069af40 0x561f10567d14 0x7fa1a471bef7 0x561f10626f97 0x561f10626da0 0x561f1069abb3 0x561f10695c35 0x561f1062873a 0x561f1069af40 0x561f10696235 0x561f1062873a 0x561f1069793b 0x561f10696235 0x561f10567e2c 0x561f10698318 0x561f10695c35 0x561f10567e2c\n",
            "tcmalloc: large alloc 1490747392 bytes == 0x56205af1c000 @  0x7fa2012db1e7 0x7fa1a46de46e 0x7fa1a472ec7b 0x7fa1a472ed18 0x7fa1a47ead79 0x7fa1a47ede4c 0x7fa1a490ce7f 0x7fa1a4912fb5 0x7fa1a4914e3d 0x7fa1a4916516 0x561f10628280 0x561f10627e59 0x7fa1a47f50db 0x561f10710e52 0x561f10697834 0x561f10695c35 0x561f1062873a 0x561f1069af40 0x561f1062865a 0x561f1069af40 0x561f10695c35 0x561f10567e2c 0x561f10698318 0x561f10695c35 0x561f10567e2c 0x561f10698318 0x561f1062865a 0x561f10696b0e 0x561f10695c35 0x561f10695933 0x561f1075f402\n",
            "changed retrieval-SfM-120k => mitsubishi_dataset\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 1.01\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:579: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(other, self)\n",
            "HOW INFO: >> Train: [1][1/128]\tTime 23.548 (23.548)\tData 20.424 (20.424)\tLoss 1.0773 (0.9265)\n",
            "HOW INFO: >> Train: [1][20/128]\tTime 1.818 (3.532)\tData 0.005 (1.519)\tLoss 0.4332 (0.5467)\n",
            "HOW INFO: >> Train: [1][40/128]\tTime 1.803 (3.027)\tData 0.002 (1.088)\tLoss 0.4853 (0.5018)\n",
            "HOW INFO: >> Train: [1][60/128]\tTime 1.804 (2.838)\tData 0.000 (0.907)\tLoss 0.4140 (0.4797)\n",
            "HOW INFO: >> Train: [1][80/128]\tTime 1.823 (2.807)\tData 0.012 (0.855)\tLoss 0.4751 (0.4644)\n",
            "HOW INFO: >> Train: [1][100/128]\tTime 1.799 (2.737)\tData 0.000 (0.780)\tLoss 0.4467 (0.4503)\n",
            "HOW INFO: >> Train: [1][120/128]\tTime 1.823 (2.696)\tData 0.000 (0.739)\tLoss 0.4094 (0.4403)\n",
            "HOW INFO: >> Train: [1][128/128]\tTime 1.631 (2.656)\tData 0.000 (0.715)\tLoss 0.4220 (0.4371)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.4370915704872459\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa177c127d0>\n",
            "######saved after 1#######\n",
            "HOW INFO: Epoch 1 finished in 460.4s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.4370915704872459\n",
            "######loaded at 1#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.55\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [2][1/128]\tTime 18.312 (18.312)\tData 15.668 (15.668)\tLoss 0.4114 (0.4242)\n",
            "HOW INFO: >> Train: [2][20/128]\tTime 1.983 (3.302)\tData 0.002 (1.258)\tLoss 0.3654 (0.4049)\n",
            "HOW INFO: >> Train: [2][40/128]\tTime 1.843 (2.883)\tData 0.007 (0.864)\tLoss 0.4035 (0.3938)\n",
            "HOW INFO: >> Train: [2][60/128]\tTime 1.831 (2.732)\tData 0.010 (0.732)\tLoss 0.3691 (0.3887)\n",
            "HOW INFO: >> Train: [2][80/128]\tTime 2.096 (2.727)\tData 0.254 (0.709)\tLoss 0.4602 (0.3884)\n",
            "HOW INFO: >> Train: [2][100/128]\tTime 1.822 (2.689)\tData 0.000 (0.692)\tLoss 0.4665 (0.3852)\n",
            "HOW INFO: >> Train: [2][120/128]\tTime 1.858 (2.653)\tData 0.000 (0.670)\tLoss 0.3611 (0.3823)\n",
            "HOW INFO: >> Train: [2][128/128]\tTime 1.629 (2.611)\tData 0.000 (0.647)\tLoss 0.4442 (0.3811)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.38110448175575584\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1db5250>\n",
            "######saved after 2#######\n",
            "HOW INFO: Epoch 2 finished in 452.2s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.38110448175575584\n",
            "######loaded at 2#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.60\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [3][1/128]\tTime 17.794 (17.794)\tData 14.684 (14.684)\tLoss 0.3640 (0.4083)\n",
            "HOW INFO: >> Train: [3][20/128]\tTime 2.637 (3.255)\tData 0.476 (1.169)\tLoss 0.3705 (0.3711)\n",
            "HOW INFO: >> Train: [3][40/128]\tTime 1.808 (2.874)\tData 0.004 (0.861)\tLoss 0.4241 (0.3619)\n",
            "HOW INFO: >> Train: [3][60/128]\tTime 1.857 (2.736)\tData 0.000 (0.742)\tLoss 0.4129 (0.3598)\n",
            "HOW INFO: >> Train: [3][80/128]\tTime 1.808 (2.742)\tData 0.010 (0.732)\tLoss 0.3141 (0.3559)\n",
            "HOW INFO: >> Train: [3][100/128]\tTime 1.780 (2.693)\tData 0.000 (0.693)\tLoss 0.2335 (0.3532)\n",
            "HOW INFO: >> Train: [3][120/128]\tTime 1.868 (2.643)\tData 0.000 (0.646)\tLoss 0.3960 (0.3518)\n",
            "HOW INFO: >> Train: [3][128/128]\tTime 1.633 (2.613)\tData 0.000 (0.632)\tLoss 0.2723 (0.3508)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.3507534746779129\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1d08550>\n",
            "######saved after 3#######\n",
            "HOW INFO: Epoch 3 finished in 450.5s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.3507534746779129\n",
            "######loaded at 3#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.59\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [4][1/128]\tTime 20.070 (20.070)\tData 18.074 (18.074)\tLoss 0.3128 (0.3417)\n",
            "HOW INFO: >> Train: [4][20/128]\tTime 1.799 (3.421)\tData 0.004 (1.541)\tLoss 0.3625 (0.3572)\n",
            "HOW INFO: >> Train: [4][40/128]\tTime 1.840 (2.952)\tData 0.009 (1.060)\tLoss 0.3896 (0.3463)\n",
            "HOW INFO: >> Train: [4][60/128]\tTime 1.878 (2.797)\tData 0.003 (0.915)\tLoss 0.2980 (0.3403)\n",
            "HOW INFO: >> Train: [4][80/128]\tTime 1.863 (2.765)\tData 0.009 (0.885)\tLoss 0.2726 (0.3360)\n",
            "HOW INFO: >> Train: [4][100/128]\tTime 1.867 (2.719)\tData 0.000 (0.846)\tLoss 0.2588 (0.3315)\n",
            "HOW INFO: >> Train: [4][120/128]\tTime 1.845 (2.683)\tData 0.000 (0.811)\tLoss 0.3211 (0.3290)\n",
            "HOW INFO: >> Train: [4][128/128]\tTime 1.638 (2.635)\tData 0.000 (0.777)\tLoss 0.3062 (0.3283)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.3282631291076541\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1da0ad0>\n",
            "######saved after 4#######\n",
            "HOW INFO: Epoch 4 finished in 453.0s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.3282631291076541\n",
            "######loaded at 4#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.56\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [5][1/128]\tTime 20.292 (20.292)\tData 18.245 (18.245)\tLoss 0.3480 (0.3940)\n",
            "HOW INFO: >> Train: [5][20/128]\tTime 1.868 (3.345)\tData 0.005 (1.428)\tLoss 0.2490 (0.3485)\n",
            "HOW INFO: >> Train: [5][40/128]\tTime 1.829 (2.926)\tData 0.011 (1.015)\tLoss 0.3564 (0.3353)\n",
            "HOW INFO: >> Train: [5][60/128]\tTime 1.870 (2.768)\tData 0.000 (0.839)\tLoss 0.3221 (0.3263)\n",
            "HOW INFO: >> Train: [5][80/128]\tTime 1.794 (2.764)\tData 0.000 (0.832)\tLoss 0.2258 (0.3214)\n",
            "HOW INFO: >> Train: [5][100/128]\tTime 1.798 (2.711)\tData 0.000 (0.785)\tLoss 0.3570 (0.3178)\n",
            "HOW INFO: >> Train: [5][120/128]\tTime 1.881 (2.677)\tData 0.000 (0.756)\tLoss 0.3456 (0.3143)\n",
            "HOW INFO: >> Train: [5][128/128]\tTime 1.635 (2.636)\tData 0.000 (0.731)\tLoss 0.2452 (0.3132)\n",
            "HOW INFO: Starting asmk evaluation\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            "WARNING clustering 727904 points to 65536 centroids: please provide at least 2555904 training points\n",
            "HOW INFO: Codebook trained in 59.7s\n",
            "HOW INFO: Evaluating 'val_eccv20'\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            ">>>> 657/657 done...\n",
            "HOW INFO: Indexed images in 13.17s\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 239/239 done...\n",
            "HOW INFO: Evaluated val_eccv20: mAP 43.6, mP@k [73.64 48.97 40.83]\n",
            "HOW INFO: Finished asmk evaluation in 4 min\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.31319811581633983\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1b32590>\n",
            "######saved after 5#######\n",
            "HOW INFO: Epoch 5 finished in 739.9s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.31319811581633983\n",
            "######loaded at 5#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.55\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [6][1/128]\tTime 18.157 (18.157)\tData 15.343 (15.343)\tLoss 0.3482 (0.3629)\n",
            "HOW INFO: >> Train: [6][20/128]\tTime 2.619 (3.326)\tData 0.552 (1.239)\tLoss 0.3003 (0.3377)\n",
            "HOW INFO: >> Train: [6][40/128]\tTime 1.892 (2.912)\tData 0.011 (0.865)\tLoss 0.2744 (0.3202)\n",
            "HOW INFO: >> Train: [6][60/128]\tTime 1.880 (2.788)\tData 0.010 (0.760)\tLoss 0.3072 (0.3121)\n",
            "HOW INFO: >> Train: [6][80/128]\tTime 1.861 (2.764)\tData 0.000 (0.736)\tLoss 0.3767 (0.3061)\n",
            "HOW INFO: >> Train: [6][100/128]\tTime 1.806 (2.708)\tData 0.005 (0.691)\tLoss 0.3501 (0.3030)\n",
            "HOW INFO: >> Train: [6][120/128]\tTime 1.830 (2.676)\tData 0.000 (0.660)\tLoss 0.2869 (0.3002)\n",
            "HOW INFO: >> Train: [6][128/128]\tTime 1.639 (2.638)\tData 0.000 (0.643)\tLoss 0.2655 (0.2993)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2992711081635207\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1e3e5d0>\n",
            "######saved after 6#######\n",
            "HOW INFO: Epoch 6 finished in 453.3s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2992711081635207\n",
            "######loaded at 6#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.56\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [7][1/128]\tTime 20.009 (20.009)\tData 17.746 (17.746)\tLoss 0.4038 (0.3564)\n",
            "HOW INFO: >> Train: [7][20/128]\tTime 1.849 (3.386)\tData 0.010 (1.466)\tLoss 0.3073 (0.3297)\n",
            "HOW INFO: >> Train: [7][40/128]\tTime 1.871 (2.942)\tData 0.010 (1.050)\tLoss 0.3149 (0.3140)\n",
            "HOW INFO: >> Train: [7][60/128]\tTime 1.886 (2.803)\tData 0.000 (0.915)\tLoss 0.2981 (0.3029)\n",
            "HOW INFO: >> Train: [7][80/128]\tTime 1.795 (2.770)\tData 0.005 (0.883)\tLoss 0.3205 (0.2993)\n",
            "HOW INFO: >> Train: [7][100/128]\tTime 1.782 (2.706)\tData 0.000 (0.823)\tLoss 0.2147 (0.2958)\n",
            "HOW INFO: >> Train: [7][120/128]\tTime 1.824 (2.659)\tData 0.006 (0.779)\tLoss 0.2982 (0.2926)\n",
            "HOW INFO: >> Train: [7][128/128]\tTime 1.633 (2.619)\tData 0.000 (0.751)\tLoss 0.3482 (0.2926)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.29258506365586073\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1771c4550>\n",
            "######saved after 7#######\n",
            "HOW INFO: Epoch 7 finished in 453.0s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.29258506365586073\n",
            "######loaded at 7#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.56\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [8][1/128]\tTime 17.969 (17.969)\tData 15.140 (15.140)\tLoss 0.3674 (0.3467)\n",
            "HOW INFO: >> Train: [8][20/128]\tTime 1.757 (3.393)\tData 0.000 (1.458)\tLoss 0.2320 (0.3234)\n",
            "HOW INFO: >> Train: [8][40/128]\tTime 1.819 (2.909)\tData 0.004 (1.003)\tLoss 0.2558 (0.3057)\n",
            "HOW INFO: >> Train: [8][60/128]\tTime 2.011 (2.761)\tData 0.005 (0.860)\tLoss 0.2309 (0.2955)\n",
            "HOW INFO: >> Train: [8][80/128]\tTime 1.852 (2.747)\tData 0.000 (0.839)\tLoss 0.2652 (0.2888)\n",
            "HOW INFO: >> Train: [8][100/128]\tTime 1.891 (2.685)\tData 0.000 (0.781)\tLoss 0.2213 (0.2844)\n",
            "HOW INFO: >> Train: [8][120/128]\tTime 1.881 (2.648)\tData 0.000 (0.734)\tLoss 0.2022 (0.2807)\n",
            "HOW INFO: >> Train: [8][128/128]\tTime 1.628 (2.605)\tData 0.000 (0.706)\tLoss 0.2947 (0.2795)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2795208567287773\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1e5b3d0>\n",
            "######saved after 8#######\n",
            "HOW INFO: Epoch 8 finished in 450.5s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2795208567287773\n",
            "######loaded at 8#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.54\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [9][1/128]\tTime 17.828 (17.828)\tData 14.692 (14.692)\tLoss 0.3535 (0.3733)\n",
            "HOW INFO: >> Train: [9][20/128]\tTime 2.010 (3.303)\tData 0.009 (1.224)\tLoss 0.2562 (0.3100)\n",
            "HOW INFO: >> Train: [9][40/128]\tTime 1.841 (2.891)\tData 0.010 (0.828)\tLoss 0.2649 (0.2853)\n",
            "HOW INFO: >> Train: [9][60/128]\tTime 1.787 (2.759)\tData 0.000 (0.716)\tLoss 0.2953 (0.2812)\n",
            "HOW INFO: >> Train: [9][80/128]\tTime 2.592 (2.744)\tData 0.346 (0.698)\tLoss 0.2760 (0.2770)\n",
            "HOW INFO: >> Train: [9][100/128]\tTime 1.803 (2.700)\tData 0.005 (0.659)\tLoss 0.2103 (0.2722)\n",
            "HOW INFO: >> Train: [9][120/128]\tTime 1.868 (2.661)\tData 0.000 (0.630)\tLoss 0.2557 (0.2705)\n",
            "HOW INFO: >> Train: [9][128/128]\tTime 1.629 (2.628)\tData 0.000 (0.617)\tLoss 0.2259 (0.2703)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.27026908011175693\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1760af790>\n",
            "######saved after 9#######\n",
            "HOW INFO: Epoch 9 finished in 451.8s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.27026908011175693\n",
            "######loaded at 9#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.58\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [10][1/128]\tTime 18.984 (18.984)\tData 16.871 (16.871)\tLoss 0.2996 (0.3257)\n",
            "HOW INFO: >> Train: [10][20/128]\tTime 1.815 (3.341)\tData 0.005 (1.432)\tLoss 0.3187 (0.2984)\n",
            "HOW INFO: >> Train: [10][40/128]\tTime 1.844 (2.929)\tData 0.004 (1.041)\tLoss 0.2448 (0.2816)\n",
            "HOW INFO: >> Train: [10][60/128]\tTime 1.922 (2.769)\tData 0.005 (0.890)\tLoss 0.3202 (0.2734)\n",
            "HOW INFO: >> Train: [10][80/128]\tTime 1.794 (2.738)\tData 0.005 (0.860)\tLoss 0.2417 (0.2694)\n",
            "HOW INFO: >> Train: [10][100/128]\tTime 1.813 (2.698)\tData 0.010 (0.821)\tLoss 0.2301 (0.2677)\n",
            "HOW INFO: >> Train: [10][120/128]\tTime 1.841 (2.661)\tData 0.000 (0.788)\tLoss 0.2515 (0.2653)\n",
            "HOW INFO: >> Train: [10][128/128]\tTime 1.623 (2.620)\tData 0.000 (0.761)\tLoss 0.2326 (0.2644)\n",
            "HOW INFO: Starting asmk evaluation\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            "WARNING clustering 727904 points to 65536 centroids: please provide at least 2555904 training points\n",
            "HOW INFO: Codebook trained in 59.5s\n",
            "HOW INFO: Evaluating 'val_eccv20'\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 657/657 done...\n",
            "HOW INFO: Indexed images in 13.14s\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 239/239 done...\n",
            "HOW INFO: Evaluated val_eccv20: mAP 42.02, mP@k [69.87 49.85 39.49]\n",
            "HOW INFO: Finished asmk evaluation in 4 min\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2643960324814543\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1ab3290>\n",
            "######saved after 10#######\n",
            "HOW INFO: Epoch 10 finished in 736.2s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2643960324814543\n",
            "######loaded at 10#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.57\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [11][1/128]\tTime 19.163 (19.163)\tData 16.600 (16.600)\tLoss 0.3571 (0.3235)\n",
            "HOW INFO: >> Train: [11][20/128]\tTime 1.803 (3.357)\tData 0.000 (1.413)\tLoss 0.2296 (0.2945)\n",
            "HOW INFO: >> Train: [11][40/128]\tTime 1.792 (2.919)\tData 0.009 (0.967)\tLoss 0.2258 (0.2742)\n",
            "HOW INFO: >> Train: [11][60/128]\tTime 1.836 (2.774)\tData 0.013 (0.822)\tLoss 0.1545 (0.2652)\n",
            "HOW INFO: >> Train: [11][80/128]\tTime 1.779 (2.747)\tData 0.004 (0.793)\tLoss 0.2129 (0.2641)\n",
            "HOW INFO: >> Train: [11][100/128]\tTime 1.855 (2.704)\tData 0.005 (0.743)\tLoss 0.2558 (0.2624)\n",
            "HOW INFO: >> Train: [11][120/128]\tTime 1.846 (2.661)\tData 0.000 (0.696)\tLoss 0.3004 (0.2609)\n",
            "HOW INFO: >> Train: [11][128/128]\tTime 1.630 (2.627)\tData 0.000 (0.679)\tLoss 0.2312 (0.2603)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.26033933635335416\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1e47450>\n",
            "######saved after 11#######\n",
            "HOW INFO: Epoch 11 finished in 452.7s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.26033933635335416\n",
            "######loaded at 11#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.58\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [12][1/128]\tTime 20.253 (20.253)\tData 18.245 (18.245)\tLoss 0.3211 (0.3122)\n",
            "HOW INFO: >> Train: [12][20/128]\tTime 1.863 (3.380)\tData 0.001 (1.508)\tLoss 0.2375 (0.2799)\n",
            "HOW INFO: >> Train: [12][40/128]\tTime 1.828 (2.968)\tData 0.009 (1.101)\tLoss 0.3079 (0.2661)\n",
            "HOW INFO: >> Train: [12][60/128]\tTime 1.831 (2.791)\tData 0.000 (0.917)\tLoss 0.2287 (0.2613)\n",
            "HOW INFO: >> Train: [12][80/128]\tTime 1.864 (2.774)\tData 0.004 (0.890)\tLoss 0.2649 (0.2581)\n",
            "HOW INFO: >> Train: [12][100/128]\tTime 1.793 (2.725)\tData 0.005 (0.835)\tLoss 0.2008 (0.2550)\n",
            "HOW INFO: >> Train: [12][120/128]\tTime 1.806 (2.687)\tData 0.000 (0.794)\tLoss 0.2808 (0.2533)\n",
            "HOW INFO: >> Train: [12][128/128]\tTime 1.627 (2.644)\tData 0.000 (0.765)\tLoss 0.1333 (0.2533)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.25332872588187455\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1e79610>\n",
            "######saved after 12#######\n",
            "HOW INFO: Epoch 12 finished in 454.3s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.25332872588187455\n",
            "######loaded at 12#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.59\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [13][1/128]\tTime 19.857 (19.857)\tData 17.220 (17.220)\tLoss 0.2929 (0.3050)\n",
            "HOW INFO: >> Train: [13][20/128]\tTime 1.834 (3.364)\tData 0.000 (1.439)\tLoss 0.2848 (0.2763)\n",
            "HOW INFO: >> Train: [13][40/128]\tTime 1.821 (2.932)\tData 0.000 (1.026)\tLoss 0.2672 (0.2640)\n",
            "HOW INFO: >> Train: [13][60/128]\tTime 1.840 (2.787)\tData 0.005 (0.892)\tLoss 0.2574 (0.2554)\n",
            "HOW INFO: >> Train: [13][80/128]\tTime 1.784 (2.771)\tData 0.009 (0.865)\tLoss 0.2389 (0.2524)\n",
            "HOW INFO: >> Train: [13][100/128]\tTime 1.808 (2.701)\tData 0.004 (0.796)\tLoss 0.2054 (0.2514)\n",
            "HOW INFO: >> Train: [13][120/128]\tTime 1.803 (2.673)\tData 0.000 (0.758)\tLoss 0.2880 (0.2509)\n",
            "HOW INFO: >> Train: [13][128/128]\tTime 1.636 (2.632)\tData 0.000 (0.732)\tLoss 0.2571 (0.2500)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.25004168435698376\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1d25a50>\n",
            "######saved after 13#######\n",
            "HOW INFO: Epoch 13 finished in 454.7s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.25004168435698376\n",
            "######loaded at 13#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.58\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [14][1/128]\tTime 18.716 (18.716)\tData 16.468 (16.468)\tLoss 0.3424 (0.3105)\n",
            "HOW INFO: >> Train: [14][20/128]\tTime 1.791 (3.377)\tData 0.000 (1.444)\tLoss 0.2283 (0.2733)\n",
            "HOW INFO: >> Train: [14][40/128]\tTime 1.890 (2.931)\tData 0.003 (1.038)\tLoss 0.2367 (0.2565)\n",
            "HOW INFO: >> Train: [14][60/128]\tTime 1.890 (2.805)\tData 0.000 (0.922)\tLoss 0.2368 (0.2496)\n",
            "HOW INFO: >> Train: [14][80/128]\tTime 1.831 (2.772)\tData 0.000 (0.887)\tLoss 0.2801 (0.2474)\n",
            "HOW INFO: >> Train: [14][100/128]\tTime 1.812 (2.709)\tData 0.000 (0.821)\tLoss 0.2453 (0.2449)\n",
            "HOW INFO: >> Train: [14][120/128]\tTime 1.842 (2.674)\tData 0.000 (0.766)\tLoss 0.2399 (0.2427)\n",
            "HOW INFO: >> Train: [14][128/128]\tTime 1.633 (2.629)\tData 0.000 (0.734)\tLoss 0.2481 (0.2425)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.24246618580073118\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1760b1090>\n",
            "######saved after 14#######\n",
            "HOW INFO: Epoch 14 finished in 453.4s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.24246618580073118\n",
            "######loaded at 14#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.59\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [15][1/128]\tTime 18.133 (18.133)\tData 15.102 (15.102)\tLoss 0.4296 (0.3140)\n",
            "HOW INFO: >> Train: [15][20/128]\tTime 3.576 (3.398)\tData 1.542 (1.297)\tLoss 0.1734 (0.2565)\n",
            "HOW INFO: >> Train: [15][40/128]\tTime 1.824 (2.904)\tData 0.005 (0.854)\tLoss 0.2367 (0.2478)\n",
            "HOW INFO: >> Train: [15][60/128]\tTime 1.823 (2.773)\tData 0.011 (0.733)\tLoss 0.1989 (0.2417)\n",
            "HOW INFO: >> Train: [15][80/128]\tTime 2.270 (2.764)\tData 0.012 (0.717)\tLoss 0.2675 (0.2406)\n",
            "HOW INFO: >> Train: [15][100/128]\tTime 1.839 (2.713)\tData 0.005 (0.673)\tLoss 0.1609 (0.2382)\n",
            "HOW INFO: >> Train: [15][120/128]\tTime 1.842 (2.669)\tData 0.000 (0.637)\tLoss 0.2685 (0.2367)\n",
            "HOW INFO: >> Train: [15][128/128]\tTime 1.638 (2.632)\tData 0.000 (0.621)\tLoss 0.2465 (0.2369)\n",
            "HOW INFO: Starting asmk evaluation\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            "WARNING clustering 727904 points to 65536 centroids: please provide at least 2555904 training points\n",
            "HOW INFO: Codebook trained in 59.3s\n",
            "HOW INFO: Evaluating 'val_eccv20'\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 657/657 done...\n",
            "HOW INFO: Indexed images in 13.97s\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 239/239 done...\n",
            "HOW INFO: Evaluated val_eccv20: mAP 44.08, mP@k [74.48 50.47 41.73]\n",
            "HOW INFO: Finished asmk evaluation in 4 min\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2369477995787747\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1a94c90>\n",
            "######saved after 15#######\n",
            "HOW INFO: Epoch 15 finished in 742.2s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2369477995787747\n",
            "######loaded at 15#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.56\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [16][1/128]\tTime 20.812 (20.812)\tData 18.436 (18.436)\tLoss 0.3413 (0.3006)\n",
            "HOW INFO: >> Train: [16][20/128]\tTime 1.913 (3.494)\tData 0.009 (1.517)\tLoss 0.2465 (0.2560)\n",
            "HOW INFO: >> Train: [16][40/128]\tTime 1.847 (3.020)\tData 0.005 (1.057)\tLoss 0.2091 (0.2456)\n",
            "HOW INFO: >> Train: [16][60/128]\tTime 1.864 (2.859)\tData 0.004 (0.888)\tLoss 0.2062 (0.2386)\n",
            "HOW INFO: >> Train: [16][80/128]\tTime 1.948 (2.837)\tData 0.000 (0.856)\tLoss 0.2273 (0.2369)\n",
            "HOW INFO: >> Train: [16][100/128]\tTime 1.904 (2.804)\tData 0.000 (0.827)\tLoss 0.3235 (0.2348)\n",
            "HOW INFO: >> Train: [16][120/128]\tTime 1.871 (2.753)\tData 0.000 (0.779)\tLoss 0.2239 (0.2349)\n",
            "HOW INFO: >> Train: [16][128/128]\tTime 1.629 (2.715)\tData 0.000 (0.759)\tLoss 0.2142 (0.2343)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23430680740857496\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1bd7850>\n",
            "######saved after 16#######\n",
            "HOW INFO: Epoch 16 finished in 467.9s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23430680740857496\n",
            "######loaded at 16#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.60\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [17][1/128]\tTime 20.633 (20.633)\tData 18.656 (18.656)\tLoss 0.2754 (0.2773)\n",
            "HOW INFO: >> Train: [17][20/128]\tTime 1.883 (3.506)\tData 0.000 (1.565)\tLoss 0.2542 (0.2575)\n",
            "HOW INFO: >> Train: [17][40/128]\tTime 1.866 (3.021)\tData 0.000 (1.104)\tLoss 0.2276 (0.2458)\n",
            "HOW INFO: >> Train: [17][60/128]\tTime 1.951 (2.892)\tData 0.005 (0.992)\tLoss 0.2198 (0.2405)\n",
            "HOW INFO: >> Train: [17][80/128]\tTime 1.877 (2.861)\tData 0.005 (0.961)\tLoss 0.2333 (0.2374)\n",
            "HOW INFO: >> Train: [17][100/128]\tTime 1.845 (2.797)\tData 0.004 (0.905)\tLoss 0.2530 (0.2367)\n",
            "HOW INFO: >> Train: [17][120/128]\tTime 2.193 (2.770)\tData 0.000 (0.879)\tLoss 0.2347 (0.2357)\n",
            "HOW INFO: >> Train: [17][128/128]\tTime 1.639 (2.717)\tData 0.000 (0.840)\tLoss 0.2791 (0.2359)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23586687803035603\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1771b6910>\n",
            "######saved after 17#######\n",
            "HOW INFO: Epoch 17 finished in 469.9s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23586687803035603\n",
            "######loaded at 17#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.60\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [18][1/128]\tTime 18.753 (18.753)\tData 16.134 (16.134)\tLoss 0.2828 (0.2831)\n",
            "HOW INFO: >> Train: [18][20/128]\tTime 1.830 (3.429)\tData 0.000 (1.376)\tLoss 0.2109 (0.2519)\n",
            "HOW INFO: >> Train: [18][40/128]\tTime 1.885 (2.999)\tData 0.000 (0.990)\tLoss 0.2471 (0.2390)\n",
            "HOW INFO: >> Train: [18][60/128]\tTime 1.909 (2.848)\tData 0.018 (0.840)\tLoss 0.2138 (0.2372)\n",
            "HOW INFO: >> Train: [18][80/128]\tTime 1.834 (2.847)\tData 0.002 (0.830)\tLoss 0.2375 (0.2359)\n",
            "HOW INFO: >> Train: [18][100/128]\tTime 1.843 (2.808)\tData 0.000 (0.808)\tLoss 0.2365 (0.2354)\n",
            "HOW INFO: >> Train: [18][120/128]\tTime 1.822 (2.770)\tData 0.000 (0.787)\tLoss 0.2278 (0.2360)\n",
            "HOW INFO: >> Train: [18][128/128]\tTime 1.637 (2.729)\tData 0.000 (0.766)\tLoss 0.2301 (0.2358)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603), (18, 0.2357601606985554)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2357601606985554\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1e9f4d0>\n",
            "######saved after 18#######\n",
            "HOW INFO: Epoch 18 finished in 473.1s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603), (18, 0.2357601606985554)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.2357601606985554\n",
            "######loaded at 18#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.61\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [19][1/128]\tTime 20.376 (20.376)\tData 17.700 (17.700)\tLoss 0.2987 (0.2783)\n",
            "HOW INFO: >> Train: [19][20/128]\tTime 1.845 (3.472)\tData 0.000 (1.465)\tLoss 0.2104 (0.2449)\n",
            "HOW INFO: >> Train: [19][40/128]\tTime 1.873 (3.044)\tData 0.008 (1.064)\tLoss 0.2441 (0.2376)\n",
            "HOW INFO: >> Train: [19][60/128]\tTime 1.921 (2.905)\tData 0.013 (0.934)\tLoss 0.2228 (0.2340)\n",
            "HOW INFO: >> Train: [19][80/128]\tTime 1.836 (2.886)\tData 0.002 (0.925)\tLoss 0.3156 (0.2339)\n",
            "HOW INFO: >> Train: [19][100/128]\tTime 1.858 (2.829)\tData 0.000 (0.879)\tLoss 0.2272 (0.2328)\n",
            "HOW INFO: >> Train: [19][120/128]\tTime 1.879 (2.790)\tData 0.000 (0.845)\tLoss 0.2404 (0.2326)\n",
            "HOW INFO: >> Train: [19][128/128]\tTime 1.631 (2.739)\tData 0.000 (0.809)\tLoss 0.2707 (0.2332)\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603), (18, 0.2357601606985554), (19, 0.23321216319454835)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23321216319454835\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1e53390>\n",
            "######saved after 19#######\n",
            "HOW INFO: Epoch 19 finished in 472.7s\n",
            "#######check loaded content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603), (18, 0.2357601606985554), (19, 0.23321216319454835)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23321216319454835\n",
            "######loaded at 19#######\n",
            ">> Creating tuples for an epoch of mitsubishi_dataset-train...\n",
            ">>>> used network: \n",
            "HOWNet(meta={\n",
            "    architecture: resnet18\n",
            "    backbone_dim: 512\n",
            "    outputdim: 128\n",
            "    corercf_size: 32\n",
            "})\n",
            ">> Extracting descriptors for query images...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 644/644 done...\n",
            ">> Extracting descriptors for negative pool...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            ">> Searching for hard negatives...\n",
            ">>>> Average negative l2-distance: 0.61\n",
            ">>>> Done\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "HOW INFO: >> Train: [20][1/128]\tTime 19.960 (19.960)\tData 17.490 (17.490)\tLoss 0.2373 (0.2814)\n",
            "HOW INFO: >> Train: [20][20/128]\tTime 1.889 (3.563)\tData 0.001 (1.622)\tLoss 0.2717 (0.2443)\n",
            "HOW INFO: >> Train: [20][40/128]\tTime 1.884 (3.054)\tData 0.004 (1.152)\tLoss 0.2378 (0.2344)\n",
            "HOW INFO: >> Train: [20][60/128]\tTime 1.996 (2.913)\tData 0.014 (1.018)\tLoss 0.2348 (0.2320)\n",
            "HOW INFO: >> Train: [20][80/128]\tTime 1.883 (2.881)\tData 0.004 (0.988)\tLoss 0.2699 (0.2314)\n",
            "HOW INFO: >> Train: [20][100/128]\tTime 1.884 (2.820)\tData 0.004 (0.918)\tLoss 0.2321 (0.2311)\n",
            "HOW INFO: >> Train: [20][120/128]\tTime 1.839 (2.774)\tData 0.000 (0.866)\tLoss 0.2563 (0.2318)\n",
            "HOW INFO: >> Train: [20][128/128]\tTime 1.633 (2.732)\tData 0.000 (0.839)\tLoss 0.2334 (0.2322)\n",
            "HOW INFO: Starting asmk evaluation\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 989/989 done...\n",
            "WARNING clustering 727904 points to 65536 centroids: please provide at least 2555904 training points\n",
            "HOW INFO: Codebook trained in 59.8s\n",
            "HOW INFO: Evaluating 'val_eccv20'\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 657/657 done...\n",
            "HOW INFO: Indexed images in 13.79s\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            ">>>> 239/239 done...\n",
            "HOW INFO: Evaluated val_eccv20: mAP 43.68, mP@k [72.38 47.5  40.97]\n",
            "HOW INFO: Finished asmk evaluation in 4 min\n",
            "#######check saved content######\n",
            "scores :  {'global_descriptor': defaultdict(<class 'list'>, {}), 'local_descriptor': defaultdict(<class 'list'>, {'val_eccv20': [(5, 0.4359813868191742), (10, 0.42022992134640386), (15, 0.440849264686539), (20, 0.4367661822139645)]}), 'train_loss': [(1, 0.4370915704872459), (2, 0.38110448175575584), (3, 0.3507534746779129), (4, 0.3282631291076541), (5, 0.31319811581633983), (6, 0.2992711081635207), (7, 0.29258506365586073), (8, 0.2795208567287773), (9, 0.27026908011175693), (10, 0.2643960324814543), (11, 0.26033933635335416), (12, 0.25332872588187455), (13, 0.25004168435698376), (14, 0.24246618580073118), (15, 0.2369477995787747), (16, 0.23430680740857496), (17, 0.23586687803035603), (18, 0.2357601606985554), (19, 0.23321216319454835), (20, 0.23215207341127098)]}\n",
            "net_params :  {'architecture': 'resnet18', 'pretrained': True, 'skip_layer': 0, 'dim_reduction': {'dim': 128}, 'smoothing': {'kernel_size': 3}, 'runtime': {'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]], 'image_size': 1024, 'features_num': 1000, 'scales': [2.0, 1.414, 1.0, 0.707, 0.5, 0.353, 0.25], 'training_scales': [1]}}\n",
            "losslogger :  0.23215207341127098\n",
            "scheduler :  <torch.optim.lr_scheduler.ExponentialLR object at 0x7fa1a1d2e150>\n",
            "######saved after 20#######\n",
            "HOW INFO: Epoch 20 finished in 765.5s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}